{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9a1e2d",
   "metadata": {},
   "source": [
    "# open img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2716db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View an image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def view_random_image(target_dir, target_class):\n",
    "  # Setup target directory (we'll view images from here)\n",
    "  target_folder = target_dir+target_class\n",
    "\n",
    "  # Get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  # Read in the image and plot it using matplotlib\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\");\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
    "\n",
    "  return img\n",
    "\n",
    "# View a random image from the training dataset\n",
    "img = view_random_image(\n",
    "  target_dir=r\"Coral Reef Images/test/\",\n",
    "  target_class=\"Bleached\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ee503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Walk through pizza_steak directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(r\"Coral Reef Images\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def trim_dataset(folder_path, keep_count=1500, dry_run=False):\n",
    "    \"\"\"\n",
    "    Keeps the first 'keep_count' images in a folder and deletes the rest.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        keep_count (int): Number of images to keep (default 1500).\n",
    "        dry_run (bool): If True, only prints what will be deleted. \n",
    "                        If False, actually deletes the files.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Check if folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        return\n",
    "\n",
    "    # 2. Get list of image files only\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter for images and sort them to ensure deterministic selection\n",
    "    image_files = sorted([f for f in all_files if f.lower().endswith(valid_extensions)])\n",
    "    \n",
    "    total_images = len(image_files)\n",
    "    print(f\"Total images found: {total_images}\")\n",
    "    \n",
    "    if total_images <= keep_count:\n",
    "        print(f\"Folder has fewer than {keep_count} images. No action needed.\")\n",
    "        return\n",
    "\n",
    "    # 3. Identify files to delete\n",
    "    # This selects everything starting from index 1500 to the end\n",
    "    files_to_delete = image_files[keep_count:]\n",
    "    \n",
    "    print(f\"Preparing to delete {len(files_to_delete)} images...\")\n",
    "\n",
    "    # 4. Delete the files\n",
    "    for img_name in files_to_delete:\n",
    "        file_path = os.path.join(folder_path, img_name)\n",
    "        \n",
    "        if dry_run:\n",
    "            # Just print, don't delete\n",
    "            print(f\"[DRY RUN] Would delete: {img_name}\")\n",
    "        else:\n",
    "            # Actually delete\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {img_name}: {e}\")\n",
    "\n",
    "    if dry_run:\n",
    "        print(\"\\n--- DRY RUN COMPLETE ---\")\n",
    "        print(f\"To actually delete these files, run the function again with dry_run=False\")\n",
    "    else:\n",
    "        print(f\"\\nSuccess! Deleted {len(files_to_delete)} images. {keep_count} remain.\")\n",
    "\n",
    "# ==========================================\n",
    "# USAGE\n",
    "# ==========================================\n",
    "\n",
    "# Define your path (using the raw string 'r' method we fixed earlier)\n",
    "my_folder = r'Coral Reef Images\\train\\Healthy'\n",
    "\n",
    "# Step 1: Run in SAFE MODE (Dry Run) first to check\n",
    "trim_dataset(my_folder, keep_count=1378, dry_run=False)\n",
    "\n",
    "# Step 2: Uncomment the line below ONLY when you are ready to delete\n",
    "# trim_dataset(my_folder, keep_count=1500, dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(\"Coral Reef Images\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f607972",
   "metadata": {},
   "source": [
    "# the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a85b2",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09500177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Make the creating of our model a little easier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras import Sequential\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edf0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "# Setup the train and test directories\n",
    "train_dir = r'Coral Reef Images/train/'\n",
    "test_dir = r'Coral Reef Images/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=32, # number of images to process at a time \n",
    "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
    "                                               class_mode=\"binary\", # type of problem we're working on\n",
    "                                               seed=42)\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"binary\",\n",
    "                                               seed=42)\n",
    "\n",
    "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters=10, \n",
    "                         kernel_size=3, # can also be (3, 3)\n",
    "                         activation=\"relu\", \n",
    "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
    "                            padding=\"valid\"), # padding can also be 'same'\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
    "  tf.keras.layers.MaxPool2D(2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706105bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves\n",
    "import pandas as pd\n",
    "pd.DataFrame(history_1.history).plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121c5ff",
   "metadata": {},
   "source": [
    "## 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode='binary',\n",
    "                                               batch_size=32)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(directory=test_dir,\n",
    "                                             target_size=(224, 224),\n",
    "                                             class_mode='binary',\n",
    "                                             batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f91b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)\n",
    "model_5 = Sequential([\n",
    "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
    "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  MaxPool2D(),\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  MaxPool2D(),\n",
    "  Flatten(),\n",
    "  Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9832222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model (same as model_4)\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history_5 = model_5.fit(train_data,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfbda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the model architecture\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf90055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves of model_5 results\n",
    "pd.DataFrame(history_5.history).plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator training instance with data augmentation\n",
    "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
    "                                             rotation_range=20, # rotate the image slightly between 0 and 20 degrees (note: this is an int not a float)\n",
    "                                             shear_range=0.2, # shear the image\n",
    "                                             zoom_range=0.2, # zoom into the image\n",
    "                                             width_shift_range=0.2, # shift the image width ways\n",
    "                                             height_shift_range=0.2, # shift the image height ways\n",
    "                                             horizontal_flip=True) # flip the image on the horizontal axis\n",
    "\n",
    "# Create ImageDataGenerator training instance without data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.) \n",
    "\n",
    "# Create ImageDataGenerator test instance without data augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ac5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and augment it from training directory\n",
    "print(\"Augmented training images:\")\n",
    "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
    "                                                                   target_size=(224, 224),\n",
    "                                                                   batch_size=32,\n",
    "                                                                   class_mode='binary',\n",
    "                                                                   shuffle=False) # Don't shuffle for demonstration purposes, usually a good thing to shuffle\n",
    "\n",
    "# Create non-augmented data batches\n",
    "print(\"Non-augmented training images:\")\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               batch_size=32,\n",
    "                                               class_mode='binary',\n",
    "                                               shuffle=False) # Don't shuffle for demonstration purposes\n",
    "\n",
    "print(\"Unchanged test images:\")\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=(224, 224),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0894691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eefeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and augment it from directories\n",
    "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
    "                                                                            target_size=(224, 224),\n",
    "                                                                            batch_size=32,\n",
    "                                                                            class_mode='binary',\n",
    "                                                                            shuffle=True) # Shuffle data (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ea03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN model (same as Tiny VGG but for binary classification - https://poloclub.github.io/cnn-explainer/ )\n",
    "model_8 = Sequential([\n",
    "  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)), # same input shape as our images\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  MaxPool2D(),\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  Conv2D(10, 3, activation='relu'),\n",
    "  MaxPool2D(),\n",
    "  Flatten(),\n",
    "  Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_8.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_8 = model_8.fit(train_data_augmented_shuffled,\n",
    "                        epochs=5,\n",
    "                        steps_per_epoch=len(train_data_augmented_shuffled),\n",
    "                        validation_data=test_data,\n",
    "                        validation_steps=len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
